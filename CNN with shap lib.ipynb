{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shap\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.3.1\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras import backend as K\n",
    "\n",
    "\n",
    "# Use TensorFlow Backend\n",
    "import tensorflow as tf\n",
    "#tf.set_random_seed(42) # For reproducibility\n",
    "\n",
    "#config = tf.ConfigProto()\n",
    "#config.gpu_options.visible_device_list = \"0\"\n",
    "#config.gpu_options.allow_growth = True\n",
    "#config.gpu_options.per_process_gpu_memory_fraction = 0.5\n",
    "#tf.Session(config=config)\n",
    "\n",
    "# Print out Keras version\n",
    "print(keras.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLflow Version: 1.10.0\n"
     ]
    }
   ],
   "source": [
    "# Including MLflow\n",
    "import mlflow\n",
    "import mlflow.keras\n",
    "import os\n",
    "print(\"MLflow Version: %s\" % mlflow.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (60000, 28, 28, 1)\n",
      "60000 train samples\n",
      "10000 test samples\n"
     ]
    }
   ],
   "source": [
    "# -----------------------------------------------------------\n",
    "# Hyperparameters\n",
    "batch_size = 128\n",
    "num_classes = 10\n",
    "epochs = 12\n",
    "\n",
    "\n",
    "# -----------------------------------------------------------\n",
    "# Image Datasets\n",
    "\n",
    "# input image dimensions\n",
    "img_rows, img_cols = 28, 28\n",
    "\n",
    "# the data, split between train and test sets\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "if K.image_data_format() == 'channels_first':\n",
    "    x_train = x_train.reshape(x_train.shape[0], 1, img_rows, img_cols)\n",
    "    x_test = x_test.reshape(x_test.shape[0], 1, img_rows, img_cols)\n",
    "    input_shape = (1, img_rows, img_cols)\n",
    "else:\n",
    "    x_train = x_train.reshape(x_train.shape[0], img_rows, img_cols, 1)\n",
    "    x_test = x_test.reshape(x_test.shape[0], img_rows, img_cols, 1)\n",
    "    input_shape = (img_rows, img_cols, 1)\n",
    "\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "x_train /= 255\n",
    "x_test /= 255\n",
    "print('x_train shape:', x_train.shape)\n",
    "print(x_train.shape[0], 'train samples')\n",
    "print(x_test.shape[0], 'test samples')\n",
    "\n",
    "# convert class vectors to binary class matrices\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 1.], dtype=float32)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train[25168,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]]\n",
      "\n",
      " [[0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]]\n",
      "\n",
      " [[0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]]\n",
      "\n",
      " [[0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]]\n",
      "\n",
      " [[0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]]\n",
      "\n",
      " [[0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]]\n",
      "\n",
      " [[0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.23921569]\n",
      "  [0.62352943]\n",
      "  [0.7607843 ]\n",
      "  [1.        ]\n",
      "  [0.8039216 ]\n",
      "  [0.23529412]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]]\n",
      "\n",
      " [[0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.28627452]\n",
      "  [0.7764706 ]\n",
      "  [0.9490196 ]\n",
      "  [0.99215686]\n",
      "  [0.99215686]\n",
      "  [0.99607843]\n",
      "  [0.99215686]\n",
      "  [0.93333334]\n",
      "  [0.22745098]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]]\n",
      "\n",
      " [[0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.24313726]\n",
      "  [0.88235295]\n",
      "  [0.99215686]\n",
      "  [0.99215686]\n",
      "  [0.99215686]\n",
      "  [0.99215686]\n",
      "  [0.99607843]\n",
      "  [0.99215686]\n",
      "  [0.99215686]\n",
      "  [0.8156863 ]\n",
      "  [0.03137255]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]]\n",
      "\n",
      " [[0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.8117647 ]\n",
      "  [0.99215686]\n",
      "  [0.99215686]\n",
      "  [0.99215686]\n",
      "  [0.99215686]\n",
      "  [0.63529414]\n",
      "  [0.6039216 ]\n",
      "  [0.38431373]\n",
      "  [0.8156863 ]\n",
      "  [0.99215686]\n",
      "  [0.2901961 ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]]\n",
      "\n",
      " [[0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.75686276]\n",
      "  [0.99215686]\n",
      "  [0.99215686]\n",
      "  [0.8666667 ]\n",
      "  [0.4       ]\n",
      "  [0.01960784]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.13333334]\n",
      "  [0.99215686]\n",
      "  [0.8745098 ]\n",
      "  [0.07058824]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]]\n",
      "\n",
      " [[0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.92156863]\n",
      "  [0.99215686]\n",
      "  [0.99215686]\n",
      "  [0.76862746]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.01176471]\n",
      "  [0.72156864]\n",
      "  [0.99215686]\n",
      "  [0.80784315]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]]\n",
      "\n",
      " [[0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.92156863]\n",
      "  [0.99215686]\n",
      "  [0.99215686]\n",
      "  [0.9254902 ]\n",
      "  [0.69803923]\n",
      "  [0.56078434]\n",
      "  [0.43137255]\n",
      "  [0.7411765 ]\n",
      "  [0.99215686]\n",
      "  [0.99215686]\n",
      "  [0.54509807]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]]\n",
      "\n",
      " [[0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.92156863]\n",
      "  [0.99215686]\n",
      "  [0.99215686]\n",
      "  [0.99215686]\n",
      "  [0.99215686]\n",
      "  [0.99215686]\n",
      "  [0.99607843]\n",
      "  [0.99215686]\n",
      "  [0.99215686]\n",
      "  [0.99215686]\n",
      "  [0.4392157 ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]]\n",
      "\n",
      " [[0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.8784314 ]\n",
      "  [0.99215686]\n",
      "  [0.99215686]\n",
      "  [0.99215686]\n",
      "  [0.99215686]\n",
      "  [0.99215686]\n",
      "  [0.99607843]\n",
      "  [0.99215686]\n",
      "  [0.99215686]\n",
      "  [0.99215686]\n",
      "  [0.16862746]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]]\n",
      "\n",
      " [[0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.41960785]\n",
      "  [0.99215686]\n",
      "  [0.99215686]\n",
      "  [0.99215686]\n",
      "  [0.99215686]\n",
      "  [0.99215686]\n",
      "  [0.99607843]\n",
      "  [0.99215686]\n",
      "  [0.99215686]\n",
      "  [0.99215686]\n",
      "  [0.57254905]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]]\n",
      "\n",
      " [[0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.32941177]\n",
      "  [0.7372549 ]\n",
      "  [0.83137256]\n",
      "  [0.7372549 ]\n",
      "  [0.7372549 ]\n",
      "  [0.5058824 ]\n",
      "  [0.37254903]\n",
      "  [0.62352943]\n",
      "  [0.99607843]\n",
      "  [0.9254902 ]\n",
      "  [0.11764706]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]]\n",
      "\n",
      " [[0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.04313726]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.59607846]\n",
      "  [0.99215686]\n",
      "  [0.99215686]\n",
      "  [0.45882353]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]]\n",
      "\n",
      " [[0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.5529412 ]\n",
      "  [0.9411765 ]\n",
      "  [0.99215686]\n",
      "  [0.92156863]\n",
      "  [0.11372549]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]]\n",
      "\n",
      " [[0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.28627452]\n",
      "  [0.95686275]\n",
      "  [0.99215686]\n",
      "  [0.99215686]\n",
      "  [0.75686276]\n",
      "  [0.0627451 ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]]\n",
      "\n",
      " [[0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.27450982]\n",
      "  [0.96862745]\n",
      "  [0.99215686]\n",
      "  [0.99215686]\n",
      "  [0.99215686]\n",
      "  [0.23529412]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]]\n",
      "\n",
      " [[0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.28627452]\n",
      "  [0.94509804]\n",
      "  [0.99607843]\n",
      "  [0.99215686]\n",
      "  [0.99215686]\n",
      "  [0.83137256]\n",
      "  [0.03921569]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]]\n",
      "\n",
      " [[0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.15686275]\n",
      "  [0.9490196 ]\n",
      "  [0.99215686]\n",
      "  [0.99607843]\n",
      "  [0.99215686]\n",
      "  [0.99215686]\n",
      "  [0.32941177]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]]\n",
      "\n",
      " [[0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.44313726]\n",
      "  [0.99215686]\n",
      "  [0.99215686]\n",
      "  [0.99607843]\n",
      "  [0.81960785]\n",
      "  [0.11764706]\n",
      "  [0.01176471]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]]\n",
      "\n",
      " [[0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.41568628]\n",
      "  [0.99215686]\n",
      "  [0.99215686]\n",
      "  [0.9647059 ]\n",
      "  [0.28627452]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]]\n",
      "\n",
      " [[0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.05882353]\n",
      "  [0.88235295]\n",
      "  [0.99215686]\n",
      "  [0.19215687]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]]\n",
      "\n",
      " [[0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]]\n",
      "\n",
      " [[0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]]]\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "# This is the extracted array for x_train = 25168 from the training matrix\n",
    "xt_25168 = x_train[25168,:]\n",
    "\n",
    "print(xt_25168)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, \n",
      "0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, \n",
      "0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, \n",
      "0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, \n",
      "0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, \n",
      "0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, \n",
      "0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.239, 0.624, 0.761, 1.000, 0.804, 0.235, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, \n",
      "0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.286, 0.776, 0.949, 0.992, 0.992, 0.996, 0.992, 0.933, 0.227, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, \n",
      "0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.243, 0.882, 0.992, 0.992, 0.992, 0.992, 0.996, 0.992, 0.992, 0.816, 0.031, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, \n",
      "0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.812, 0.992, 0.992, 0.992, 0.992, 0.635, 0.604, 0.384, 0.816, 0.992, 0.290, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, \n",
      "0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.757, 0.992, 0.992, 0.867, 0.400, 0.020, 0.000, 0.000, 0.133, 0.992, 0.875, 0.071, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, \n",
      "0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.922, 0.992, 0.992, 0.769, 0.000, 0.000, 0.000, 0.012, 0.722, 0.992, 0.808, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, \n",
      "0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.922, 0.992, 0.992, 0.925, 0.698, 0.561, 0.431, 0.741, 0.992, 0.992, 0.545, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, \n",
      "0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.922, 0.992, 0.992, 0.992, 0.992, 0.992, 0.996, 0.992, 0.992, 0.992, 0.439, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, \n",
      "0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.878, 0.992, 0.992, 0.992, 0.992, 0.992, 0.996, 0.992, 0.992, 0.992, 0.169, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, \n",
      "0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.420, 0.992, 0.992, 0.992, 0.992, 0.992, 0.996, 0.992, 0.992, 0.992, 0.573, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, \n",
      "0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.329, 0.737, 0.831, 0.737, 0.737, 0.506, 0.373, 0.624, 0.996, 0.925, 0.118, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, \n",
      "0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.043, 0.000, 0.000, 0.000, 0.000, 0.596, 0.992, 0.992, 0.459, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, \n",
      "0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.553, 0.941, 0.992, 0.922, 0.114, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, \n",
      "0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.286, 0.957, 0.992, 0.992, 0.757, 0.063, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, \n",
      "0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.275, 0.969, 0.992, 0.992, 0.992, 0.235, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, \n",
      "0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.286, 0.945, 0.996, 0.992, 0.992, 0.831, 0.039, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, \n",
      "0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.157, 0.949, 0.992, 0.996, 0.992, 0.992, 0.329, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, \n",
      "0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.443, 0.992, 0.992, 0.996, 0.820, 0.118, 0.012, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, \n",
      "0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.416, 0.992, 0.992, 0.965, 0.286, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, \n",
      "0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.059, 0.882, 0.992, 0.192, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, \n",
      "0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000, \n"
     ]
    }
   ],
   "source": [
    "# As this is a 28 x 28 image, let's print it out this way\n",
    "txt = \"\"\n",
    "for i in range (0, 27):\n",
    "    for j in range(0, 27):\n",
    "        val = \"%.3f\" % xt_25168[i,j]\n",
    "        txt += str(val).replace(\"[\", \"\").replace(\"]\", \"\") + \", \"\n",
    "   \n",
    "    print(txt)\n",
    "    txt = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def runCNN(activation, verbose):\n",
    "  # Building up our CNN\n",
    "  model = Sequential()\n",
    "  \n",
    "  # Convolution Layer\n",
    "  model.add(Conv2D(32, kernel_size=(3, 3),\n",
    "                 activation=activation,\n",
    "                 input_shape=input_shape)) \n",
    "  \n",
    "  # Convolution layer\n",
    "  model.add(Conv2D(64, (3, 3), activation=activation))\n",
    "  \n",
    "  # Pooling with stride (2, 2)\n",
    "  model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "  \n",
    "  # Delete neuron randomly while training (remain 75%)\n",
    "  #   Regularization technique to avoid overfitting\n",
    "  model.add(Dropout(0.25))\n",
    "  \n",
    "  # Flatten layer \n",
    "  model.add(Flatten())\n",
    "  \n",
    "  # Fully connected Layer\n",
    "  model.add(Dense(128, activation=activation))\n",
    "  \n",
    "  # Delete neuron randomly while training (remain 50%) \n",
    "  #   Regularization technique to avoid overfitting\n",
    "  model.add(Dropout(0.5))\n",
    "  \n",
    "  # Apply Softmax\n",
    "  model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "  # Log MLflow\n",
    "  #with mlflow.start_run(experiment_id = mlflow_experiment_id) as run:\n",
    "  with mlflow.start_run() as run:\n",
    "  \n",
    "    # Loss function (crossentropy) and Optimizer (Adadelta)\n",
    "    model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "              optimizer=keras.optimizers.Adadelta(),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "    # Fit our model\n",
    "    model.fit(x_train, y_train,\n",
    "          batch_size=batch_size,\n",
    "          epochs=epochs,\n",
    "          verbose=verbose,\n",
    "          validation_data=(x_test, y_test))\n",
    "\n",
    "    # Evaluate our model\n",
    "    score = model.evaluate(x_test, y_test, verbose=0)\n",
    "\n",
    "    # Log Parameters\n",
    "    mlflow.log_param(\"activation function\", activation)\n",
    "    mlflow.log_metric(\"test loss\", score[0])\n",
    "    mlflow.log_metric(\"test accuracy\", score[1])\n",
    "    \n",
    "    # Log Model\n",
    "    mlflow.keras.log_model(model, \"model\")\n",
    "    \n",
    "  # Return\n",
    "  return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nitin/anaconda3/lib/python3.7/site-packages/keras/engine/training_utils.py:811: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated since Python 3.3,and in 3.9 it will stop working\n",
      "  if isinstance(loss, collections.Mapping):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.10485499833747744\n",
      "Test accuracy: 0.9700999855995178\n"
     ]
    }
   ],
   "source": [
    "score_sigmoid = runCNN('sigmoid', 0)\n",
    "print('Test loss:', score_sigmoid[0])\n",
    "print('Test accuracy:', score_sigmoid[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.03565137563325989\n",
      "Test accuracy: 0.989300012588501\n"
     ]
    }
   ],
   "source": [
    "score_tanh = runCNN('tanh', 0)\n",
    "print('Test loss:', score_tanh[0])\n",
    "print('Test accuracy:', score_tanh[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/12\n",
      "60000/60000 [==============================] - 51s 849us/step - loss: 0.2685 - accuracy: 0.9190 - val_loss: 0.0760 - val_accuracy: 0.9751\n",
      "Epoch 2/12\n",
      "60000/60000 [==============================] - 51s 846us/step - loss: 0.0876 - accuracy: 0.9747 - val_loss: 0.0430 - val_accuracy: 0.9859\n",
      "Epoch 3/12\n",
      "60000/60000 [==============================] - 51s 844us/step - loss: 0.0681 - accuracy: 0.9800 - val_loss: 0.0355 - val_accuracy: 0.9881\n",
      "Epoch 4/12\n",
      "60000/60000 [==============================] - 51s 845us/step - loss: 0.0530 - accuracy: 0.9840 - val_loss: 0.0324 - val_accuracy: 0.9889\n",
      "Epoch 5/12\n",
      "60000/60000 [==============================] - 51s 845us/step - loss: 0.0477 - accuracy: 0.9857 - val_loss: 0.0301 - val_accuracy: 0.9889\n",
      "Epoch 6/12\n",
      "60000/60000 [==============================] - 51s 845us/step - loss: 0.0408 - accuracy: 0.9875 - val_loss: 0.0301 - val_accuracy: 0.9897\n",
      "Epoch 7/12\n",
      "60000/60000 [==============================] - 51s 847us/step - loss: 0.0370 - accuracy: 0.9887 - val_loss: 0.0268 - val_accuracy: 0.9919\n",
      "Epoch 8/12\n",
      "60000/60000 [==============================] - 51s 846us/step - loss: 0.0336 - accuracy: 0.9896 - val_loss: 0.0288 - val_accuracy: 0.9911\n",
      "Epoch 9/12\n",
      "60000/60000 [==============================] - 51s 845us/step - loss: 0.0317 - accuracy: 0.9901 - val_loss: 0.0257 - val_accuracy: 0.9911\n",
      "Epoch 10/12\n",
      "60000/60000 [==============================] - 51s 844us/step - loss: 0.0295 - accuracy: 0.9911 - val_loss: 0.0260 - val_accuracy: 0.9909\n",
      "Epoch 11/12\n",
      "60000/60000 [==============================] - 51s 846us/step - loss: 0.0272 - accuracy: 0.9915 - val_loss: 0.0253 - val_accuracy: 0.9915\n",
      "Epoch 12/12\n",
      "60000/60000 [==============================] - 51s 846us/step - loss: 0.0255 - accuracy: 0.9920 - val_loss: 0.0245 - val_accuracy: 0.9922\n"
     ]
    }
   ],
   "source": [
    "# Building up our CNN\n",
    "model = Sequential()\n",
    "\n",
    "# Convolution Layer\n",
    "model.add(Conv2D(32, kernel_size=(3, 3),\n",
    "               activation='relu',\n",
    "               input_shape=input_shape)) \n",
    "\n",
    "# Convolution layer\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "\n",
    "# Pooling with stride (2, 2)\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "# Delete neuron randomly while training (remain 75%)\n",
    "#   Regularization technique to avoid overfitting\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "# Flatten layer \n",
    "model.add(Flatten())\n",
    "\n",
    "# Fully connected Layer\n",
    "model.add(Dense(128, activation='relu'))\n",
    "\n",
    "# Delete neuron randomly while training (remain 50%) \n",
    "#   Regularization technique to avoid overfitting\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "# Apply Softmax\n",
    "model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "# Log MLflow\n",
    "#with mlflow.start_run(experiment_id = mlflow_experiment_id) as run:\n",
    "with mlflow.start_run() as run:\n",
    "\n",
    "  # Loss function (crossentropy) and Optimizer (Adadelta)\n",
    "  model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "            optimizer=keras.optimizers.Adadelta(),\n",
    "            metrics=['accuracy'])\n",
    "\n",
    "  # Fit our model\n",
    "  model.fit(x_train, y_train,\n",
    "        batch_size=batch_size,\n",
    "        epochs=epochs,\n",
    "        verbose=1,\n",
    "        validation_data=(x_test, y_test))\n",
    "\n",
    "  # Evaluate our model\n",
    "  score = model.evaluate(x_test, y_test, verbose=0)\n",
    "\n",
    "  # Log Parameters\n",
    "  mlflow.log_param(\"activation function\", 'relu')\n",
    "  mlflow.log_metric(\"test loss\", score[0])\n",
    "  mlflow.log_metric(\"test accuracy\", score[1])\n",
    "\n",
    "  # Log Model\n",
    "  mlflow.keras.log_model(model, \"model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.024468238703090173\n",
      "Test accuracy: 0.9922000169754028\n"
     ]
    }
   ],
   "source": [
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import shap\n",
    "import numpy as np\n",
    "\n",
    "# select a set of background examples to take an expectation over\n",
    "background = x_train[np.random.choice(x_train.shape[0], 100, replace=False)]\n",
    "\n",
    "# explain predictions of the model on three images\n",
    "e = shap.DeepExplainer(model, background)\n",
    "# ...or pass tensors directly\n",
    "# e = shap.DeepExplainer((model.layers[0].input, model.layers[-1].output), background)\n",
    "shap_values = e.shap_values(x_test[1:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the feature attributions\n",
    "shap_plot = shap.image_plot(shap_values, -x_test[1:5])\n",
    "display(shap_plot)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the feature attributions\n",
    "shap_plot = shap.image_plot(shap_values, -x_test[1:10])\n",
    "display(shap_plot)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the feature attributions\n",
    "shap_plot = shap.image_plot(shap_values, -x_test[11:20])\n",
    "display(shap_plot)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# https://databricks.com/wp-content/uploads/2019/10/Introduction-to-Neural-Networks-MLflow-and-SHAP.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
